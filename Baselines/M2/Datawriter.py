import re
import os
import numpy as np
import random
from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer
import math, operator
import fasttext
from tqdm import tqdm
import pickle
from collections import Counter

#from nltk.stem import WordNetLemmatizer
#stemmer = WordNetLemmatizer()


malicious_directory = '../mspd/malicious_pure'
benign_directory = '../mspd/powershell_benign_dataset'
mixed_malicious_directory = '../mspd/mixed_malicious'
obfuscated_mixed_directory = '../../mspd/STRING_obfuscated_mixed'

def preprocessing(directory):
    scripts = []
    count = 5
    for filename in tqdm(list(os.scandir(directory))):
        # if count == 0:
        #     break

        if filename.is_file():
            with open(filename, encoding="ISO-8859-1") as f:
                lines = f.readlines()

            f.close()

            document = []

            if len(lines) == 0: #some obfuscated files are empty.
                continue
                
            for sen in range(len(lines)):

                # Remove all the special characters
                sent = re.sub(r'\W', ' ', str(lines[sen]))
                
                #sent = str(lines[sen])
                # Remove single characters from the start
                sent = re.sub(r'\[^a-zA-Z*"$"]\s+', ' ', sent) 

                # Substituting multiple spaces with single space
                sent = re.sub(r'\s+', ' ', sent, flags=re.I)

                # Converting to Lowercase
                sent = sent.lower()
                
                if len(sent.strip()) > 0:
                    document.extend(sent.split())
  
                 #document.append(sent)
#                 newdoc = []
#                 for i in range(len(document)):
#                     if document[i] != ' ':
#                         newdoc += document[i].split()
            count -= 1
            newdoc = ' '.join(document)
            scripts.append(newdoc)
    return scripts

    
def CharLvlExtraction(script):
    script = script.replace(" ", "")
    vec=[]
    Entropy = 0
    totalWord = len(script)
    for char in tqdm(script):
        p = (script.count(char))/totalWord
        Entropy += p * math.log(p)
    Entropy *= -1
    
    
    counter = Counter(script).most_common(5)
    for i in range(5):
        vec.append(ord(counter[i][0]))
    return vec+[Entropy] #first 5 are ascii encode top 5 character and 6th is Entropy




def WordLvlExtraction(script):


    Shellcode_flag, URL_flag = 0, 0
    
    #script in type of <str>
    if "0x" in script:
        Shellcode_flag = 1
    if (("http" in script) or (".exe" in script)):
        URL_flag = 1
    totLenStr = len(script)
    special_names = script.count("cmd") + script.count("Shell")
    
    #script in type of <list>
    script = script.split()
    maxLenStr = len(max(script, key=len))
    numStr = len(script)
    special_names += script.count("c")
    avgLenStr = (totLenStr-numStr+1)/numStr # this is because when counting total length of string, it counts the space (" ") between words as well, so we need to substract them.
    
    return [Shellcode_flag, numStr, maxLenStr, avgLenStr, URL_flag, special_names]
        
        



    

def pretrainFT():
    bscripts = preprocessing(benign_directory)
    mscripts = preprocessing(malicious_directory)
    #mixedscripts = preprocessing(mixed_malicious_directory)
    
    f = open("./pretrain.txt", "w")
    for sp in mscripts:
        f.write("__label__"+str(1)+" "+sp+'\n')
    
    for sp in bscripts:
        f.write("__label__"+str(0)+" "+sp+'\n')
        
    f.close()
    


    FTmodel = fasttext.train_supervised(input="./pretrain.txt", wordNgrams=2, dim=300, maxn=10, minn=2, epoch=25)
    FTmodel.save_model("model_bm.bin")
    print("All done!")
    
    
        
    

def writeData():
    
#     bscripts = preprocessing(benign_directory)
#     mscripts = preprocessing(malicious_directory)
    # mixedscripts = preprocessing(mixed_malicious_directory)
    obfuscript = preprocessing(obfuscated_mixed_directory)
    
    bVec, mVec, MixVec, ObsVec = [], [], [], []

    
    FTmodel = fasttext.load_model("model_bm.bin")
    
#     with open('./benign.pkl', 'wb') as fb:
#         #bscripts = preprocessing(benign_directory)
#         for bs in tqdm(bscripts):
#             Semantic_vec=[]
#             results = FTmodel.predict(bs)
#             if results[0] == ('__label__0',):
#                 Semantic_vec.append(0)
#             else:
#                 Semantic_vec.append(1)
#             Semantic_vec+=results[1].tolist()
#             #finalVec = CharLvlExtraction(bs) + WordLvlExtraction(bs)+[0]
#             finalVec = Semantic_vec + CharLvlExtraction(bs) + WordLvlExtraction(bs)
#             bVec.append(finalVec)
#         pickle.dump(bVec, fb)
#         print("All done!")


#     with open('./malicious.pkl', 'wb') as fm:
#         #mscripts = preprocessing(malicious_directory)
#         for ms in tqdm(mscripts):
#             Semantic_vec=[]
#             results = FTmodel.predict(ms)
#             if results[0] == ('__label__0',):
#                 Semantic_vec.append(0)
#             else:
#                 Semantic_vec.append(1)
#             Semantic_vec+=results[1].tolist()
#             #finalVec = CharLvlExtraction(ms) + WordLvlExtraction(ms)+[1]
#             finalVec = Semantic_vec + CharLvlExtraction(ms) + WordLvlExtraction(ms)
#             mVec.append(finalVec)
#         pickle.dump(mVec, fm)
#         print("All done!")


#     with open('./Mixed.pkl', 'wb') as fm:
#         for mx in tqdm(mixedscripts):
#             Semantic_vec=[]
#             results = FTmodel.predict(mx)
#             if results[0] == ('__label__0',):
#                 Semantic_vec.append(0)
#             else:
                
#                 Semantic_vec.append(1)
#             Semantic_vec+=results[1].tolist()
#             #finalVec = CharLvlExtraction(mx) + WordLvlExtraction(mx)+[1]
#             finalVec = Semantic_vec + CharLvlExtraction(mx) + WordLvlExtraction(mx)
#             MixVec.append(finalVec)
#         pickle.dump(MixVec, fm)
#         print("All done!")
        
    with open('./STRING_Obfuscation.pkl', 'wb') as fo:
        for ob in tqdm(obfuscript):
            Semantic_vec=[]
            results = FTmodel.predict(ob)
            if results[0] == ('__label__0',):
                Semantic_vec.append(0)
            else:
                
                Semantic_vec.append(1)
            Semantic_vec+=results[1].tolist()
            #finalVec = CharLvlExtraction(mx) + WordLvlExtraction(mx)+[1]
            finalVec = Semantic_vec + CharLvlExtraction(ob) + WordLvlExtraction(ob)
            ObsVec.append(finalVec)
        pickle.dump(ObsVec, fo)
        print("All done!")
    
    
    
        
        
        

    






            

            
if __name__ == "__main__":
#     os.environ["CUDA_VISIBLE_DEVICES"] = "0"
#     X_train, X_test, y_train, y_test, Mix_X, Mix_y = generateData()



    writeData()
    with open('./STRING_Obfuscation.pkl', 'rb') as f:
        mynewlist = pickle.load(f)
    print(len(mynewlist))    
    
    # obfuscript = preprocessing(obfuscated_mixed_directory)
    # print(obfuscript)

